{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bea235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "from typing import Callable, List, Tuple, Any\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Helper: run the DP assuming m ≤ n (code identical to your original logic)\n",
    "# --------------------------------------------------------------------------\n",
    "def _align_core(m: int,\n",
    "                n: int,\n",
    "                cost: Callable[[int, int], float],\n",
    "                invalid: float = inf\n",
    ") -> Tuple[float, List[Tuple[int, int]]]:\n",
    "    \"\"\"Core DP: requires m ≤ n.\"\"\"\n",
    "    dp   = [[invalid]*(n+1) for _ in range(m+1)]\n",
    "    prev = [[-1]     *(n+1) for _ in range(m+1)]\n",
    "\n",
    "    for j in range(1, n+1):          # base row i = 1\n",
    "        dp[1][j]   = cost(1, j)\n",
    "        prev[1][j] = 0\n",
    "\n",
    "    for i in range(2, m+1):          # inductive rows\n",
    "        for j in range(1, n+1):\n",
    "            best = invalid\n",
    "            argk = -1\n",
    "            for k in range(1, j):    # k < j\n",
    "                cand = dp[i-1][k] + cost(i, j)\n",
    "                if cand < best:\n",
    "                    best, argk = cand, k\n",
    "            dp[i][j]   = best\n",
    "            prev[i][j] = argk\n",
    "\n",
    "    opt_cost, j_star = min((dp[m][j], j) for j in range(1, n+1))\n",
    "    if opt_cost == invalid:\n",
    "        return inf, []               # no feasible subsequence (shouldn’t happen)\n",
    "    align = []\n",
    "    j = j_star\n",
    "    for i in range(m, 0, -1):\n",
    "        align.append((i, j))\n",
    "        j = prev[i][j]\n",
    "    align.reverse()\n",
    "    return opt_cost, align\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# Public wrapper that handles m > n by swapping arguments\n",
    "# --------------------------------------------------------------------------\n",
    "def align_rows(m: int,\n",
    "               n: int,\n",
    "               cost: Callable[[int, int], float],\n",
    "               invalid: float = inf\n",
    ") -> Tuple[float, List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Order‑preserving minimum‑cost alignment of m predicted rows to n true rows.\n",
    "    Works for any m, n ≥ 0.  When m > n the function returns the best alignment\n",
    "    for a *subset* of the predicted rows (those paired in the output list).\n",
    "    Unmatched predicted rows can be treated later as false positives.\n",
    "    \"\"\"\n",
    "    if m == 0 or n == 0:\n",
    "        return inf, []\n",
    "\n",
    "    # Case 1: m ≤ n – run the core DP directly\n",
    "    if m <= n:\n",
    "        return _align_core(m, n, cost, invalid)\n",
    "\n",
    "    # Case 2: m > n – swap roles so the shorter table is the \"predicted\" one\n",
    "    def cost_swapped(i: int, j: int) -> float:\n",
    "        # i now refers to original true row index, j to original predicted row\n",
    "        return cost(j, i)\n",
    "\n",
    "    opt_cost, swapped_align = _align_core(n, m, cost_swapped, invalid)\n",
    "    if not swapped_align:\n",
    "        return inf, []\n",
    "\n",
    "    # swapped_align gives (true_idx, pred_idx); invert to (pred_idx, true_idx)\n",
    "    align = [(pred, true) for true, pred in swapped_align]\n",
    "    align.sort()  # ensure increasing order in predicted-table indices\n",
    "\n",
    "    return opt_cost, align\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93139dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "Optimal cost  : 1.188\n",
      "1 0\n",
      "[('Spots', 'missing'), ('Ch', 'WMGL'), ('Day', 'Tu'), ('Air Date', 'missing'), ('Air Time', '6:23 AM'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')]\n",
      "[('Spots', 'missing'), ('#', 3), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '3:47 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')]\n",
      "2 1\n",
      "[('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'missing'), ('Air Date', '09/05/23'), ('Air Time', '9:39 AM'), ('Description', 'M-F'), ('Start/End Time', '6a-10a'), ('Length', 'missing'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]\n",
      "[('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '4:16 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Utility: Jaccard similarity between two rows (tuples of key–value pairs)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "from typing import List, Tuple, Any, Set\n",
    "\n",
    "KVPair = Tuple[Any, Any]   # (key, value) ; key & value can be any hashables\n",
    "Row    = List[KVPair]      # a table row is a list of KV pairs\n",
    "\n",
    "def _kvset(row: Row) -> Set[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Normalise a row of KV pairs into a set of lowercase strings so that\n",
    "    ('Price', '$10 ') and ('price', '$10') are treated as the same.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        (str(k).strip().lower(), str(v).strip().lower())\n",
    "        for k, v in row\n",
    "    }\n",
    "\n",
    "def jaccard_row_sim(row_pred: Row, row_true: Row) -> float:\n",
    "    \"\"\"\n",
    "    Jaccard similarity between two rows represented as lists of KV pairs.\n",
    "    1.0 = perfect match, 0.0 = no overlap.\n",
    "    \"\"\"\n",
    "    set_pred = _kvset(row_pred)\n",
    "    set_true = _kvset(row_true)\n",
    "\n",
    "    if not set_pred and not set_true:          # both rows empty\n",
    "        return 1.0\n",
    "\n",
    "    intersection = len(set_pred & set_true)\n",
    "    union        = len(set_pred | set_true)\n",
    "\n",
    "    # print(set_pred)\n",
    "    # print(set_true)\n",
    "    # print(intersection, union) \n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Cost function w(i,j) for the DP:\n",
    "# w = 1 – Jaccard similarity\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def make_cost_fn(table_pred: List[Row], table_true: List[Row]):\n",
    "    \"\"\"\n",
    "    Returns a closure w(i,j) suitable for align_rows().\n",
    "    Indices i, j are 1‑based to match the DP.\n",
    "    \"\"\"\n",
    "    def w(i: int, j: int) -> float:\n",
    "        sim = jaccard_row_sim(table_pred[i-1], table_true[j-1])\n",
    "        # print(i,table_pred[i-1])\n",
    "        # print(j,table_true[j-1])\n",
    "        # print(sim)\n",
    "        return 1.0 - sim            # cost ≥ 0 ; lower is better\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Example usage with the align_rows() routine defined earlier\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Ground‑truth table (T1) : list of rows; each row is list of KV pairs\n",
    "    T1 = [[('Spots', 'missing'), ('#', 3), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '3:47 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')], [('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '4:16 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]]\n",
    "    T2= [[('Spots', 'missing'), ('#', 1), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Time', 'missing'), ('Description', 'M-F'), ('Start/End Time', 'missing'), ('Length', 'missing'), ('Ad-ID', 'missing'), ('Rate', '$20.00')], [('Spots', 'missing'), ('Ch', 'WMGL'), ('Day', 'Tu'), ('Air Date', 'missing'), ('Air Time', '6:23 AM'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')], [('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'missing'), ('Air Date', '09/05/23'), ('Air Time', '9:39 AM'), ('Description', 'M-F'), ('Start/End Time', '6a-10a'), ('Length', 'missing'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]]\n",
    "\n",
    "    m, n = len(T2), len(T1)\n",
    "    print(m,n)\n",
    "    w = make_cost_fn(T2, T1)\n",
    "\n",
    "    # for i in range(1,m+1):\n",
    "    #     for j in range(1,n+1):\n",
    "    #         print('row i:', i-1, T2[i-1])\n",
    "    #         print('row j:', j-1, T1[j-1])\n",
    "    #         print(w(i,j))\n",
    "\n",
    "    opt_cost, alignment = align_rows(m, n, w)\n",
    "\n",
    "    print(f\"Optimal cost  : {opt_cost:.3f}\")\n",
    "    #print(\"Row alignment :\", alignment)\n",
    "    for pairs in alignment:\n",
    "        i = pairs[0] - 1\n",
    "        j = pairs[1] - 1\n",
    "        print(i,j)\n",
    "        print(T2[i])\n",
    "        print(T1[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b9c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Precision: 0.167\n",
      "Table Recall   : 0.208\n",
      "Table F1       : 0.185\n",
      "\n",
      "Per-predicted-row PRF1 (precision focus):\n",
      "  Pred row 0: P=0.50, R=0.42, F1=0.45\n",
      "  Pred row 1: P=0.00, R=0.00, F1=0.00\n",
      "  Pred row 2: P=0.00, R=0.00, F1=0.00\n",
      "\n",
      "Per-true-row PRF1 (recall focus):\n",
      "  True row 0: P=0.50, R=0.42, F1=0.45\n",
      "  True row 1: P=0.00, R=0.00, F1=0.00\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Tuple, Any, Iterable\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "import trix\n",
    "\n",
    "KVPair   = Tuple[Any, Any]      # (key, value)\n",
    "Row      = List[KVPair]         # tuple = list of KV pairs\n",
    "Match    = Tuple[int, int]      # (pred_row_index, true_row_index), 0-based\n",
    "\n",
    "def normalise(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    if s.isdigit():               # purely numeric → drop leading zeros\n",
    "        s = s.lstrip(\"0\") or \"0\"  # keep at least one zero\n",
    "    return s.lower()\n",
    "\n",
    "# ------------------------- Normalization helper ------------------------- #\n",
    "def _kv_set(row: Row) -> set:\n",
    "    \"\"\"Normalise a row of KV pairs to a set of (key, value) strings.\"\"\"\n",
    "    return {\n",
    "        (str(k).strip().lower(), str(v).strip().lower())\n",
    "        for k, v in row\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------ equality\n",
    "def eval_eq(a: str, b: str) -> int:\n",
    "    \"\"\"\n",
    "    Placeholder for the user‑supplied equality function.\n",
    "    Returns 1 if two strings should be considered equal.\n",
    "    \"\"\"\n",
    "    a = normalise(a)\n",
    "    b = normalise(b)\n",
    "    if a == 'true' and b == '\\uf0fc':\n",
    "        return 1\n",
    "    if b == 'true' and a == '\\uf0fc':\n",
    "        return 1\n",
    "    return trix.equal(a,b) \n",
    "\n",
    "# ------------------------------------------------------------------ PRF1 data\n",
    "@dataclass\n",
    "class PRF1:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "\n",
    "# ------------------------------------------------------------------ scoring\n",
    "def tuple_prf1(\n",
    "    pred_row: Row,\n",
    "    true_row: Row,\n",
    "    value_eq: Callable[[str, str], int] = eval_eq\n",
    ") -> PRF1:\n",
    "    pred_pairs: List[KVPair] = [\n",
    "        (str(k).strip().lower(), str(v).strip()) for k, v in pred_row\n",
    "    ]\n",
    "    true_pairs: List[KVPair] = [\n",
    "        (str(k).strip().lower(), str(v).strip()) for k, v in true_row\n",
    "    ]\n",
    "\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "\n",
    "    for k_pred, v_pred in pred_pairs:\n",
    "        for k_true, v_true in true_pairs:\n",
    "            if value_eq(k_pred, k_true) == 1 and value_eq(v_pred, v_true) == 1:\n",
    "                precision += 1\n",
    "                break\n",
    "    \n",
    "    for k_true, v_true in true_pairs:\n",
    "        for k_pred, v_pred in pred_pairs:\n",
    "            if value_eq(k_pred, k_true) == 1 and value_eq(v_pred, v_true) == 1:\n",
    "                recall += 1\n",
    "                break\n",
    "    if len(pred_pairs) > 0:\n",
    "        precision /= len(pred_pairs)\n",
    "    if len(true_pairs) > 0:\n",
    "        recall /= len(true_pairs)\n",
    "\n",
    "\n",
    "    # \"\"\"\n",
    "    # Precision / Recall / F1 for a predicted vs. true row, using\n",
    "    # a custom equality test `value_eq(a, b) -> 0/1` on *values*.\n",
    "\n",
    "    # • Keys are matched after case‑/whitespace‑normalising.\n",
    "    # • Each true KV pair can be matched at most once (greedy one‑to‑one).\n",
    "    # \"\"\"\n",
    "    # # normalise keys once\n",
    "    # pred_pairs: List[KVPair] = [\n",
    "    #     (str(k).strip().lower(), str(v).strip()) for k, v in pred_row\n",
    "    # ]\n",
    "    # true_pairs: List[KVPair] = [\n",
    "    #     (str(k).strip().lower(), str(v).strip()) for k, v in true_row\n",
    "    # ]\n",
    "\n",
    "    # used_true = [False] * len(true_pairs)\n",
    "    # tp = 0\n",
    "\n",
    "    # for k_pred, v_pred in pred_pairs:\n",
    "    #     # find first unused true pair with same key and value_eq == 1\n",
    "    #     match_idx = -1\n",
    "    #     for j, (k_true, v_true) in enumerate(true_pairs):\n",
    "    #         if not used_true[j] and k_pred == k_true and value_eq(v_pred, v_true) == 1:\n",
    "    #             match_idx = j\n",
    "    #             break\n",
    "    #     if match_idx >= 0:\n",
    "    #         used_true[match_idx] = True\n",
    "    #         tp += 1\n",
    "\n",
    "    # fp = len(pred_pairs) - tp\n",
    "    # fn = len(true_pairs) - tp\n",
    "\n",
    "    # precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    # recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1        = (2 * precision * recall / (precision + recall)\n",
    "                 if (precision + recall) else 0.0)\n",
    "    return PRF1(precision, recall, f1)\n",
    "\n",
    "\n",
    "# -------------------- Table-level Precision / Recall / F1 -------------------- #\n",
    "@dataclass\n",
    "class TablePRF1:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    per_tuple_pred: List[PRF1]\n",
    "    per_tuple_true: List[PRF1]\n",
    "\n",
    "def table_prf1(\n",
    "    pred_table: List[Row],\n",
    "    true_table: List[Row],\n",
    "    matches: Iterable[Match]\n",
    ") -> TablePRF1:\n",
    "    \"\"\"\n",
    "    Compute table-level precision, recall, F1.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    pred_table  : list of predicted tuples (rows, each a list of KV pairs)\n",
    "    true_table  : list of ground-truth tuples\n",
    "    matches     : iterable of (p_i, t_j) where row p_i in pred_table is matched\n",
    "                  to row t_j in true_table. Indices are 0-based and one-to-one.\n",
    "\n",
    "    Definitions (as per your instructions):\n",
    "    ---------------------------------------\n",
    "    - Tuple-level PRF1 is computed only for matched pairs.\n",
    "    - Table-level Precision: average over all predicted tuples:\n",
    "         * if a predicted tuple is matched, use its tuple precision\n",
    "         * if unmatched, precision = 0\n",
    "    - Table-level Recall: average over all true tuples:\n",
    "         * if a true tuple is matched, use its tuple recall\n",
    "         * if unmatched, recall = 0\n",
    "    - Table-level F1: harmonic mean of the above precision & recall.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    TablePRF1 dataclass with overall P/R/F1 and lists of per-tuple PRF1 stats.\n",
    "    \"\"\"\n",
    "    # Build quick lookup from matches\n",
    "    match_dict_pred = {p-1: t-1 for p, t in matches}\n",
    "    match_dict_true = {t-1: p-1 for p, t in matches}\n",
    "\n",
    "    # print(match_dict_pred)\n",
    "    # print(match_dict_true)\n",
    "\n",
    "    # 1) per-predicted-row precision list\n",
    "    #print('checking precision...')\n",
    "    per_tuple_pred: List[PRF1] = []\n",
    "    for p_idx, p_row in enumerate(pred_table):\n",
    "        #print(p_idx)\n",
    "        if p_idx in match_dict_pred:\n",
    "            t_idx = match_dict_pred[p_idx]\n",
    "            #print(p_row)\n",
    "            #print(true_table[t_idx])\n",
    "            prf1 = tuple_prf1(p_row, true_table[t_idx])\n",
    "            #print(prf1.precision) \n",
    "        else:\n",
    "            prf1 = PRF1(precision=0.0, recall=0.0, f1=0.0)\n",
    "        per_tuple_pred.append(prf1)\n",
    "\n",
    "    # 2) per-true-row recall list\n",
    "    per_tuple_true: List[PRF1] = []\n",
    "    for t_idx, t_row in enumerate(true_table):\n",
    "        if t_idx in match_dict_true:\n",
    "            p_idx = match_dict_true[t_idx]\n",
    "            prf1 = tuple_prf1(pred_table[p_idx], t_row)\n",
    "        else:\n",
    "            prf1 = PRF1(precision=0.0, recall=0.0, f1=0.0)\n",
    "        per_tuple_true.append(prf1)\n",
    "\n",
    "    # 3) aggregate\n",
    "    table_precision = sum(r.precision for r in per_tuple_pred) / len(pred_table) if pred_table else 0.0\n",
    "    table_recall    = sum(r.recall    for r in per_tuple_true) / len(true_table) if true_table else 0.0\n",
    "    table_f1        = (2 * table_precision * table_recall / (table_precision + table_recall)\n",
    "                       if (table_precision + table_recall) else 0.0)\n",
    "\n",
    "    return TablePRF1(table_precision, table_recall, table_f1, per_tuple_pred, per_tuple_true)\n",
    "\n",
    "def table_sim(table_t,table_p):\n",
    "    m, n = len(table_p), len(table_t)\n",
    "    w = make_cost_fn(table_p, table_t)\n",
    "    opt_cost, alignment = align_rows(m, n, w)\n",
    "    #print(alignment)\n",
    "    table_metrics = table_prf1(table_p, table_t, alignment)\n",
    "    return table_metrics \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    T1 = [[('Spots', 'missing'), ('#', 3), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '3:47 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')], [('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Date', '09/04/23'), ('Air Time', '4:16 PM'), ('Description', 'M-F'), ('Start/End Time', '3p-7p'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]]\n",
    "    T2= [[('Spots', 'missing'), ('#', 1), ('Ch', 'WMGL'), ('Day', 'M'), ('Air Time', 'missing'), ('Description', 'M-F'), ('Start/End Time', 'missing'), ('Length', 'missing'), ('Ad-ID', 'missing'), ('Rate', '$20.00')], [('Spots', 'missing'), ('Ch', 'WMGL'), ('Day', 'Tu'), ('Air Date', 'missing'), ('Air Time', '6:23 AM'), ('Length', ':30'), ('Ad-ID', 'MOORE SPOT 2'), ('Rate', '$20.00'), ('Type', 'NM')], [('Spots', 'missing'), ('#', 2), ('Ch', 'WMGL'), ('Day', 'missing'), ('Air Date', '09/05/23'), ('Air Time', '9:39 AM'), ('Description', 'M-F'), ('Start/End Time', '6a-10a'), ('Length', 'missing'), ('Ad-ID', 'MOORE SPOT 1'), ('Rate', '$20.00'), ('Type', 'NM')]]\n",
    "    matches = [(1,1)]\n",
    "\n",
    "    table_metrics = table_prf1(T2, T1, matches)\n",
    "\n",
    "    print(f\"Table Precision: {table_metrics.precision:.3f}\")\n",
    "    print(f\"Table Recall   : {table_metrics.recall:.3f}\")\n",
    "    print(f\"Table F1       : {table_metrics.f1:.3f}\")\n",
    "\n",
    "    print(\"\\nPer-predicted-row PRF1 (precision focus):\")\n",
    "    for i, r in enumerate(table_metrics.per_tuple_pred):\n",
    "        print(f\"  Pred row {i}: P={r.precision:.2f}, R={r.recall:.2f}, F1={r.f1:.2f}\")\n",
    "\n",
    "    print(\"\\nPer-true-row PRF1 (recall focus):\")\n",
    "    for j, r in enumerate(table_metrics.per_tuple_true):\n",
    "        print(f\"  True row {j}: P={r.precision:.2f}, R={r.recall:.2f}, F1={r.f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07e016cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Tuple, Any, Set\n",
    "\n",
    "KVPair = Tuple[Any, Any]  # (key, value)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PRF1:\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "\n",
    "\n",
    "def _kv_normalize(kv: Iterable[KVPair]) -> Set[Tuple[str, str]]:\n",
    "    \"\"\"Normalize to lowercase, stripped strings for robust equality.\"\"\"\n",
    "    return {\n",
    "        (str(k).strip().lower(), str(v).strip().lower())\n",
    "        for k, v in kv\n",
    "    }\n",
    "\n",
    "\n",
    "def kv_prf1(kv_pred: Iterable[KVPair], kv_true: Iterable[KVPair]) -> PRF1:\n",
    "    \"\"\"\n",
    "    Compute precision, recall, and F1 between two sets of key–value pairs.\n",
    "\n",
    "    Precision = |kv_pred ∩ kv_true| / |kv_pred|\n",
    "    Recall    = |kv_pred ∩ kv_true| / |kv_true|\n",
    "    F1        = 2 * P * R / (P + R)\n",
    "    \"\"\"\n",
    "    P = _kv_normalize(kv_pred)\n",
    "    G = _kv_normalize(kv_true)\n",
    "\n",
    "    tp = len(P & G)\n",
    "    fp = len(P - G)\n",
    "    fn = len(G - P)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1        = (2 * precision * recall / (precision + recall)) if (precision + recall) else 0.0\n",
    "    return (precision, recall, f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4450e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json  \n",
    "\n",
    "def scan_folder(path, filter_file_type = '.json'):\n",
    "    file_names = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_name = os.path.join(root, file)\n",
    "            if('DS_Store' in file_name):\n",
    "                continue\n",
    "            if(filter_file_type not in file_name):\n",
    "                continue\n",
    "            file_names.append(file_name)\n",
    "    return file_names\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b317174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_kvs(data):\n",
    "#     kvs = []\n",
    "#     for kv in data:\n",
    "#         tuples = list(kv.items())\n",
    "#         kvs += tuples\n",
    "#     return kvs \n",
    "\n",
    "def get_kvs(data):\n",
    "    \"\"\"\n",
    "    Flatten a list of dicts into a list of (key, value) tuples,\n",
    "    **skipping** entries whose key *and* value are both empty.\n",
    "\n",
    "    An entry is considered “empty” if:\n",
    "      • the key, once converted to string and stripped, is \"\",  **and**\n",
    "      • the value is None  **or** its string‑stripped form is \"\".\n",
    "    \"\"\"\n",
    "    kvs = []\n",
    "    for kv in data:       \n",
    "        if len(kv) == 0:\n",
    "            continue                 # each kv is a dict\n",
    "        for k, v in kv.items():\n",
    "            key_empty   = str(k).strip() == \"\"\n",
    "            val_empty   = (v is None) or str(v).strip() == \"\"\n",
    "            if key_empty and val_empty:   # skip the all‑empty pair\n",
    "                continue\n",
    "            kvs.append((k, v))\n",
    "    return kvs\n",
    "\n",
    "\n",
    "def get_table(data):\n",
    "    table = []\n",
    "    for tuple in data:\n",
    "        tuple_l = list(tuple.items()) \n",
    "        table.append(tuple_l)\n",
    "    return table \n",
    "\n",
    "def get_data(path):\n",
    "    data = read_json(path)\n",
    "    result = []\n",
    "    id_list = []\n",
    "    for rec in data:#scan one record \n",
    "        #print(rec)\n",
    "        rec_o = {}\n",
    "        rid = rec['id']\n",
    "        if rid in id_list:\n",
    "            continue \n",
    "        id_list.append(rid) \n",
    "        content = rec['content']\n",
    "        #print(rid, content)\n",
    "        rec_o['id'] = rid \n",
    "        content_o = []\n",
    "        for block in content:#scan one data block \n",
    "            block_o = {}\n",
    "            #print(block['type'])\n",
    "            if block['type'] == 'table':\n",
    "                table = get_table(block['content'])\n",
    "                block_o['type'] = block['type']\n",
    "                block_o['content'] = table\n",
    "            if block['type'] == 'kv':\n",
    "                kvs = get_kvs(block['content'])\n",
    "                block_o['type'] = block['type']\n",
    "                block_o['content'] = kvs \n",
    "            if len(block_o) > 0:\n",
    "                content_o.append(block_o)\n",
    "        rec_o['content'] = content_o \n",
    "        result.append(rec_o)\n",
    "    \n",
    "    return result \n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "parent_directory = str(Path().resolve().parent)\n",
    "truth_folder_path = parent_directory + '/data'\n",
    "files = scan_folder(truth_folder_path)\n",
    "# for file in files:\n",
    "#     print(file)\n",
    "#     data = read_json(file) \n",
    "#     result = display_data(data)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9d9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'cherry', 'date']\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ------------------------------------------------------------------ helpers\n",
    "def _to_set(lst: List[str]) -> set:\n",
    "    return {s.strip().lower() for s in lst}\n",
    "\n",
    "def jaccard(a: List[str], b: List[str]) -> float:\n",
    "    sa, sb = _to_set(a), _to_set(b)\n",
    "    if not sa and not sb:\n",
    "        return 1.0\n",
    "    return len(sa & sb) / len(sa | sb)\n",
    "\n",
    "# ----------------------------------------------------------------- result\n",
    "@dataclass\n",
    "class BestMatch:\n",
    "    idx0: int          # zero‑based position in Bs   (0 → first list)\n",
    "    similarity: float  # Jaccard similarity\n",
    "    candidate: List[str]\n",
    "\n",
    "# ------------------------------------------------------------ main routine\n",
    "def most_similar(A: List[str], Bs: List[List[str]]) -> BestMatch:\n",
    "    best_idx0, best_sim = -1, -1.0\n",
    "    for i, B in enumerate(Bs):\n",
    "        sim = jaccard(A, B)\n",
    "        if sim > best_sim:\n",
    "            best_idx0, best_sim = i, sim\n",
    "    return BestMatch(\n",
    "        idx0=best_idx0,\n",
    "        similarity=best_sim,\n",
    "        candidate=Bs[best_idx0] if best_idx0 >= 0 else []\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    A  = [\"Apple\", \"Banana\", \"Cherry\"]\n",
    "    B1 = [\"banana\", \"cherry\", \"durian\"]\n",
    "    B2 = [\"fig\", \"grape\"]\n",
    "    B3 = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
    "\n",
    "    best = most_similar(A, [B1, B2, B3])\n",
    "    print(best.candidate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a87b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(table):\n",
    "    schema = []\n",
    "    if len(table) == 0:\n",
    "        return schema\n",
    "    tuple = table[0]\n",
    "    for cell in tuple:\n",
    "        schema.append(cell[0])\n",
    "    return schema \n",
    "\n",
    "def eval_tables(rec_t,rec_p):\n",
    "    #get table schema for all predicted tables \n",
    "    schema_p = []\n",
    "    rid = 0\n",
    "    tid = 0\n",
    "    mp = {}\n",
    "    for block in rec_p['content']:\n",
    "        if block['type'] == 'table':\n",
    "            schema_p.append(get_schema(block['content'])) \n",
    "            mp[tid] = rid \n",
    "            tid += 1\n",
    "        rid += 1 \n",
    "\n",
    "    #print(mp)\n",
    "\n",
    "\n",
    "    table_metrics = []\n",
    "    for block in rec_t['content']:\n",
    "        if block['type'] == 'table':\n",
    "            cur_schema = get_schema(block['content'])\n",
    "            target = most_similar(cur_schema, schema_p)\n",
    "            #print('true schema:', cur_schema)\n",
    "            #print('target schema:', target.candidate) \n",
    "            idx = target.idx0 \n",
    "            \n",
    "            o_idx = mp[idx] \n",
    "            # print(idx, o_idx)\n",
    "            #print('truth1:', block['content'])\n",
    "            #print('pred1:', rec_p['content'][o_idx]['content'])\n",
    "            table_metric = table_sim(block['content'], rec_p['content'][o_idx]['content']) \n",
    "            #print(table_metric.precision, table_metric.recall, table_metric.f1)\n",
    "            table_metrics.append(table_metric)\n",
    "    \n",
    "    #count average table precision\n",
    "    precision_c = 0\n",
    "    tab_precision = 0\n",
    "    for metric in table_metrics:\n",
    "        for i, r in enumerate(metric.per_tuple_pred):\n",
    "            tab_precision += r.precision\n",
    "            precision_c += 1\n",
    "\n",
    "    #count average table recall\n",
    "    recall_c = 0\n",
    "    tab_recall = 0\n",
    "    for metric in table_metrics:\n",
    "        for i, r in enumerate(metric.per_tuple_true):\n",
    "            tab_recall += r.recall\n",
    "            recall_c += 1\n",
    "    \n",
    "    tab_precision = tab_precision / precision_c\n",
    "    tab_recall = tab_recall / recall_c\n",
    "    tab_F1 = 2*tab_precision*tab_recall/(tab_precision + tab_recall) \n",
    "\n",
    "    return tab_precision, tab_recall, tab_F1\n",
    "\n",
    "def merge_tables(rec):\n",
    "    table = []\n",
    "    for block in rec['content']:\n",
    "        if block['type'] == 'table':\n",
    "            table += block['content'] \n",
    "    return table \n",
    "\n",
    "def eval_concat_table(rec_t,rec_p):\n",
    "    merged_tab_t = merge_tables(rec_t)\n",
    "    merged_tab_p = merge_tables(rec_p) \n",
    "    # print(merged_tab_t)\n",
    "    # print(merged_tab_p) \n",
    "    table_metric = table_sim(merged_tab_t, merged_tab_p)\n",
    "    return table_metric.precision, table_metric.recall, table_metric.f1, len(merged_tab_t), len(merged_tab_p)\n",
    "\n",
    "def eval_structure_accuracy_record_pair(rec_t,rec_p):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    F1 = 0\n",
    "    kvs_t = []\n",
    "    kvs_p = []\n",
    "    kv_recall_c = 0\n",
    "    kv_precision_c = 0\n",
    "    #eval kvs \n",
    "    \n",
    "    for block in rec_t['content']:#scan each block \n",
    "        #print('true:', block)\n",
    "        if block['type'] == 'kv':\n",
    "            kvs_t += block['content']\n",
    "            kv_recall_c += 1\n",
    "    \n",
    "    for block in rec_p['content']:\n",
    "        #print('pred:', block)\n",
    "        if block['type'] == 'kv':\n",
    "            kvs_p += block['content']\n",
    "            kv_precision_c += 1\n",
    "\n",
    "    # print(kvs_t)\n",
    "    # print(kvs_p)\n",
    "    (kvs_precision, kvs_recall, kvs_F1) = kv_prf1(kvs_t,kvs_p) \n",
    "\n",
    "    #print('kvs:', kvs_precision, kvs_recall, kvs_F1, kv_precision_c, kv_recall_c)\n",
    "\n",
    "    #eval tables \n",
    "    tab_precision, tab_recall, tab_F1, recall_c,precision_c  = eval_concat_table(rec_t, rec_p) \n",
    "    #print('tables:', tab_precision, tab_recall, tab_F1)\n",
    "    \n",
    "    precision = (tab_precision*precision_c + kvs_precision * kv_precision_c) / (precision_c + kv_precision_c)\n",
    "    recall = (tab_recall*recall_c + kvs_recall * kv_recall_c) / (recall_c + kv_recall_c)\n",
    "    if (precision + recall) > 0:\n",
    "        F1 = 2*precision*recall/(precision + recall) \n",
    "    else:\n",
    "        F1 = 0\n",
    "\n",
    "    return precision, recall, F1, tab_precision, tab_recall, tab_F1, kvs_precision, kvs_recall, kvs_F1\n",
    "\n",
    "\n",
    "def eval_structure_accuracy(truth_path, result_path):\n",
    "    truth = get_data(truth_path)\n",
    "    result = get_data(result_path)\n",
    "    avg_precision = 0\n",
    "    avg_recall = 0\n",
    "    avg_F1 = 0\n",
    "    #print(len(truth))\n",
    "    size = min(len(truth), len(result))\n",
    "    for i in range(size):\n",
    "        rec_t = truth[i]\n",
    "        rec_p = result[i]\n",
    "        # print('truth:',rec_t)\n",
    "        # print('pred:', rec_p)\n",
    "        precision, recall, F1, tab_precision, tab_recall, tab_F1, kvs_precision, kvs_recall, kvs_F1 = eval_structure_accuracy_record_pair(rec_t, rec_p)\n",
    "        avg_precision += precision\n",
    "        avg_recall += recall\n",
    "        avg_F1 += F1\n",
    "        #print(i, precision, recall, F1)\n",
    "        #break \n",
    "    \n",
    "    avg_precision /= size\n",
    "    avg_recall /= size\n",
    "    avg_F1 /= size\n",
    "    #print(avg_precision, avg_recall, avg_F1)\n",
    "    return avg_precision, avg_recall, avg_F1\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv(path):\n",
    "    return pd.read_csv(path) \n",
    "\n",
    "def get_difficult_labels():\n",
    "    parent_directory = str(Path().resolve().parent)\n",
    "    path = parent_directory + '/difficulties.csv' \n",
    "    df = read_csv(path)\n",
    "    labels = dict(zip(df['name'], df['complexity']))\n",
    "    #print(labels)   \n",
    "    return labels         \n",
    "\n",
    "def get_complexity(labels, file_name):\n",
    "    for doc, complexity in labels.items():\n",
    "        if doc.lower() in file_name.lower():\n",
    "            return complexity\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e371ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_2_end_structure_eval(approach):    \n",
    "    current_folder = os.getcwd()\n",
    "    parent_folder = os.path.dirname(current_folder)\n",
    "    pdf_folder_path = parent_folder + '/data/raw'\n",
    "    pdfs = scan_folder(pdf_folder_path,'.pdf')\n",
    "    #approach = 'TRIX' \n",
    "    labels = get_difficult_labels()\n",
    "\n",
    "    #print(labels)\n",
    "\n",
    "    easy_p = 0\n",
    "    easy_r = 0\n",
    "    easy_f = 0\n",
    "    medium_p = 0\n",
    "    medium_r = 0\n",
    "    medium_f = 0\n",
    "    hard_p = 0\n",
    "    hard_r = 0\n",
    "    hard_f = 0\n",
    "\n",
    "    easy_cnt = 0\n",
    "    medium_cnt = 0\n",
    "    hard_cnt = 0\n",
    "\n",
    "    for pdf_path in pdfs:\n",
    "        \n",
    "        result_path = ''\n",
    "        if approach == 'TRIX':\n",
    "            result_path = pdf_path.replace('data/raw','out').replace('.pdf','_TRIX.json')\n",
    "        if approach == 'Eva_D': \n",
    "            result_path = pdf_path.replace('data/raw','out').replace('.pdf','_Eva_D.json')\n",
    "        if approach == 'AzureDI':\n",
    "            result_path = pdf_path.replace('data/raw','out').replace('.pdf','_AzureDI.json')\n",
    "        if approach == 'TEXTRACT':\n",
    "            result_path = pdf_path.replace('data/raw','out').replace('.pdf','_TEXTRACT.json')\n",
    "        if approach == 'vLLMS':\n",
    "            result_path = pdf_path.replace('data/raw','out').replace('.pdf','_vLLMS.json')\n",
    "\n",
    "        #print(result_path)\n",
    "        if(not os.path.isfile(result_path)):\n",
    "            continue \n",
    "\n",
    "        truth_path = pdf_path.replace('raw','truths').replace('.pdf','.json')\n",
    "        #print(truth_path)\n",
    "        if(not os.path.isfile(truth_path)):\n",
    "            continue \n",
    "\n",
    "        complexity = get_complexity(labels, pdf_path)\n",
    "        \n",
    "        #print(complexity, truth_path, result_path)\n",
    "        precision, recall, F1 = eval_structure_accuracy(truth_path, result_path)\n",
    "        #print(precision, recall, F1)\n",
    "\n",
    "        if complexity == 1:\n",
    "            easy_p += precision\n",
    "            easy_r += recall\n",
    "            easy_f += F1\n",
    "            easy_cnt += 1\n",
    "        elif complexity == 2:\n",
    "            medium_p += precision\n",
    "            medium_r += recall\n",
    "            medium_f += F1\n",
    "            medium_cnt += 1\n",
    "        elif complexity == 3:\n",
    "            hard_p += precision\n",
    "            hard_r += recall\n",
    "            hard_f += F1\n",
    "            hard_cnt += 1\n",
    "        \n",
    "    if easy_cnt > 0:\n",
    "        easy_p /= easy_cnt\n",
    "        easy_r /= easy_cnt\n",
    "        easy_f /= easy_cnt\n",
    "\n",
    "    if medium_cnt > 0:\n",
    "        medium_p /= medium_cnt\n",
    "        medium_r /= medium_cnt\n",
    "        medium_f /= medium_cnt\n",
    "\n",
    "    if hard_cnt > 0:\n",
    "        hard_p /= hard_cnt\n",
    "        hard_r /= hard_cnt\n",
    "        hard_f /= hard_cnt\n",
    "\n",
    "    print('Easy datasets: P|R|F1', easy_p, easy_r, easy_f)\n",
    "    print('Medium datasets: P|R|F1', medium_p, medium_r, medium_f)\n",
    "    print('Hard datasets: P|R|F1', hard_p, hard_r, hard_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae7e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easy datasets: P|R|F1 0.9360922755688295 0.914446983452787 0.9241207981220811\n",
      "Medium datasets: P|R|F1 0.812131693682935 0.7584461761208132 0.769161505073607\n",
      "Hard datasets: P|R|F1 0.7928959838335872 0.7639237166560547 0.7653608673041603\n"
     ]
    }
   ],
   "source": [
    "approach = 'TRIX'\n",
    "\n",
    "end_2_end_structure_eval(approach)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
